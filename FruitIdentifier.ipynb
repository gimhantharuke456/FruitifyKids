{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5rxIwJOephP",
        "outputId": "0e1fd8e5-a197-47a2-aa31-84c3b87e3488"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set download directory\n",
        "download_dir = \"/content/drive/MyDrive/Kaggle\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(download_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# Upload kaggle.json (if not already uploaded)\n",
        "from google.colab import files\n",
        "\n",
        "# Option 1: Upload kaggle.json directly in Colab\n",
        "# Uncomment the next line if you haven't uploaded the kaggle.json yet\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# Configure Kaggle\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "!cp /content/drive/MyDrive/Kaggle/kaggle.json /root/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# Import and authenticate Kaggle API\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AcoyHuAfZTa",
        "outputId": "592dd1e0-a389-42ec-b085-81b11267ba55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/kritikseth/fruit-and-vegetable-image-recognition\n",
            "Downloaded files to: /content/drive/MyDrive/Kaggle/fruit_dataset\n"
          ]
        }
      ],
      "source": [
        "download_dir = \"/content/drive/MyDrive/Kaggle/fruit_dataset\"\n",
        "api.dataset_download_files('kritikseth/fruit-and-vegetable-image-recognition', path=download_dir, unzip=True)\n",
        "\n",
        "print(f\"Downloaded files to: {download_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nMubGQoKgcLp"
      },
      "outputs": [],
      "source": [
        "train_path='/content/drive/MyDrive/Kaggle/fruit_dataset/train'\n",
        "test_path='/content/drive/MyDrive/Kaggle/fruit_dataset/test'\n",
        "val_path='/content/drive/MyDrive/Kaggle/fruit_dataset/validation'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CdSCIJ3hGIw",
        "outputId": "09f3812d-431f-4d1e-bc7b-0609aac36f9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categories in train set:  36\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print('Categories in train set: ',len(os.listdir(os.path.join(train_path))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXPUJAlChINR",
        "outputId": "f6b6ccbc-f9be-47fb-f229-a9915772e855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['apple', 'banana', 'beetroot', 'bell pepper', 'cabbage', 'capsicum', 'carrot', 'cauliflower', 'chilli pepper', 'corn', 'cucumber', 'eggplant', 'garlic', 'ginger', 'grapes', 'jalepeno', 'kiwi', 'lemon', 'lettuce', 'mango', 'onion', 'orange', 'paprika', 'pear', 'peas', 'pineapple', 'pomegranate', 'potato', 'raddish', 'soy beans', 'spinach', 'sweetcorn', 'sweetpotato', 'tomato', 'turnip', 'watermelon']\n"
          ]
        }
      ],
      "source": [
        "print(os.listdir(os.path.join(train_path)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HablYoDthKsw"
      },
      "outputs": [],
      "source": [
        "class_names = os.listdir(os.path.join(train_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOsTUrEvhMju",
        "outputId": "915f2dd9-23b9-430a-bdc8-bc60dd1a7382"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['apple',\n",
              " 'banana',\n",
              " 'beetroot',\n",
              " 'bell pepper',\n",
              " 'cabbage',\n",
              " 'capsicum',\n",
              " 'carrot',\n",
              " 'cauliflower',\n",
              " 'chilli pepper',\n",
              " 'corn',\n",
              " 'cucumber',\n",
              " 'eggplant',\n",
              " 'garlic',\n",
              " 'ginger',\n",
              " 'grapes',\n",
              " 'jalepeno',\n",
              " 'kiwi',\n",
              " 'lemon',\n",
              " 'lettuce',\n",
              " 'mango',\n",
              " 'onion',\n",
              " 'orange',\n",
              " 'paprika',\n",
              " 'pear',\n",
              " 'peas',\n",
              " 'pineapple',\n",
              " 'pomegranate',\n",
              " 'potato',\n",
              " 'raddish',\n",
              " 'soy beans',\n",
              " 'spinach',\n",
              " 'sweetcorn',\n",
              " 'sweetpotato',\n",
              " 'tomato',\n",
              " 'turnip',\n",
              " 'watermelon']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRCg8rgZhO16",
        "outputId": "5869169e-1aa6-4920-8018-24ad65241656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3115 images belonging to 36 classes.\n",
            "Class Indices: {'apple': 0, 'banana': 1, 'beetroot': 2, 'bell pepper': 3, 'cabbage': 4, 'capsicum': 5, 'carrot': 6, 'cauliflower': 7, 'chilli pepper': 8, 'corn': 9, 'cucumber': 10, 'eggplant': 11, 'garlic': 12, 'ginger': 13, 'grapes': 14, 'jalepeno': 15, 'kiwi': 16, 'lemon': 17, 'lettuce': 18, 'mango': 19, 'onion': 20, 'orange': 21, 'paprika': 22, 'pear': 23, 'peas': 24, 'pineapple': 25, 'pomegranate': 26, 'potato': 27, 'raddish': 28, 'soy beans': 29, 'spinach': 30, 'sweetcorn': 31, 'sweetpotato': 32, 'tomato': 33, 'turnip': 34, 'watermelon': 35}\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the path for training images\n",
        "train_path = '/content/drive/MyDrive/Kaggle/fruit_dataset/train'\n",
        "\n",
        "# Create an ImageDataGenerator for preprocessing and augmenting images\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,  # Normalize pixel values between 0 and 1\n",
        "    rotation_range=20,    # Randomly rotate images\n",
        "    width_shift_range=0.2,  # Randomly shift images horizontally\n",
        "    height_shift_range=0.2,  # Randomly shift images vertically\n",
        "    shear_range=0.2,        # Randomly apply shearing\n",
        "    zoom_range=0.2,         # Randomly zoom in/out\n",
        "    horizontal_flip=True,   # Randomly flip images horizontally\n",
        "    fill_mode='nearest'     # Fill missing pixels after transformations\n",
        ")\n",
        "\n",
        "# Create a train generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(150, 150),  # Resize images to a fixed size (adjustable)\n",
        "    batch_size=32,          # Number of images per batch\n",
        "    class_mode='categorical'  # Output labels as one-hot encoded\n",
        ")\n",
        "\n",
        "# Print the class indices (folder names mapped to labels)\n",
        "print(\"Class Indices:\", train_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYOiiHH4haAk",
        "outputId": "b9610f8b-4306-428e-dead-b77188a1d40e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 359 images belonging to 36 classes.\n",
            "Found 351 images belonging to 36 classes.\n",
            "Class Indices (Validation): {'apple': 0, 'banana': 1, 'beetroot': 2, 'bell pepper': 3, 'cabbage': 4, 'capsicum': 5, 'carrot': 6, 'cauliflower': 7, 'chilli pepper': 8, 'corn': 9, 'cucumber': 10, 'eggplant': 11, 'garlic': 12, 'ginger': 13, 'grapes': 14, 'jalepeno': 15, 'kiwi': 16, 'lemon': 17, 'lettuce': 18, 'mango': 19, 'onion': 20, 'orange': 21, 'paprika': 22, 'pear': 23, 'peas': 24, 'pineapple': 25, 'pomegranate': 26, 'potato': 27, 'raddish': 28, 'soy beans': 29, 'spinach': 30, 'sweetcorn': 31, 'sweetpotato': 32, 'tomato': 33, 'turnip': 34, 'watermelon': 35}\n",
            "Class Indices (Test): {'apple': 0, 'banana': 1, 'beetroot': 2, 'bell pepper': 3, 'cabbage': 4, 'capsicum': 5, 'carrot': 6, 'cauliflower': 7, 'chilli pepper': 8, 'corn': 9, 'cucumber': 10, 'eggplant': 11, 'garlic': 12, 'ginger': 13, 'grapes': 14, 'jalepeno': 15, 'kiwi': 16, 'lemon': 17, 'lettuce': 18, 'mango': 19, 'onion': 20, 'orange': 21, 'paprika': 22, 'pear': 23, 'peas': 24, 'pineapple': 25, 'pomegranate': 26, 'potato': 27, 'raddish': 28, 'soy beans': 29, 'spinach': 30, 'sweetcorn': 31, 'sweetpotato': 32, 'tomato': 33, 'turnip': 34, 'watermelon': 35}\n"
          ]
        }
      ],
      "source": [
        "# Test Data Generator (No data augmentation, just rescaling)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(150, 150),  # Resize images to the same size as train data\n",
        "    batch_size=32,          # Number of images per batch\n",
        "    class_mode='categorical',  # Output labels as one-hot encoded\n",
        "    shuffle=False            # Do not shuffle for evaluation\n",
        ")\n",
        "\n",
        "# Validation Data Generator (No data augmentation, just rescaling)\n",
        "val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(150, 150),  # Resize images to the same size as train data\n",
        "    batch_size=32,          # Number of images per batch\n",
        "    class_mode='categorical',  # Output labels as one-hot encoded\n",
        "    shuffle=False            # Do not shuffle for validation\n",
        ")\n",
        "\n",
        "# Print the class indices for reference\n",
        "print(\"Class Indices (Validation):\", val_generator.class_indices)\n",
        "print(\"Class Indices (Test):\", test_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tMhI6V47hcXA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "Mg3vv53LheGa",
        "outputId": "6673f647-ff87-449e-db85-85c8141dee2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ inception_v3 (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2048\u001b[0m)          │      \u001b[38;5;34m21,802,784\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m262,272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)                  │           \u001b[38;5;34m4,644\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)          │      <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,644</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,069,700\u001b[0m (84.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,069,700</span> (84.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,035,268\u001b[0m (84.06 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,035,268</span> (84.06 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m34,432\u001b[0m (134.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,432</span> (134.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the InceptionV3 model pre-trained on ImageNet, exclude the top layers\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "\n",
        "# Freeze the base model layers (to retain pre-trained weights)\n",
        "base_model.trainable = True\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    base_model,  # InceptionV3 as the base model\n",
        "    GlobalAveragePooling2D(),  # Replace Flatten layer\n",
        "    Dense(128, activation='relu'),  # Dense layer\n",
        "    Dropout(0.5),  # Dropout for regularization\n",
        "    Dense(len(train_generator.class_indices), activation='softmax')  # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMa4hda6hiBg",
        "outputId": "8723a5fb-ef23-44b1-d070-0d0dc4f5c7d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m 6/97\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16:48\u001b[0m 11s/step - accuracy: 0.0972 - loss: 3.6957"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1553s\u001b[0m 14s/step - accuracy: 0.1245 - loss: 3.3949 - val_accuracy: 0.0219 - val_loss: 768.5425\n",
            "Epoch 2/15\n",
            "\u001b[1m 1/97\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 166ms/step - accuracy: 0.2500 - loss: 2.8048"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 205ms/step - accuracy: 0.2500 - loss: 2.8048 - val_accuracy: 0.3226 - val_loss: 876.1423\n",
            "Epoch 3/15\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 1s/step - accuracy: 0.2809 - loss: 2.7154 - val_accuracy: 0.0938 - val_loss: 24.1345\n",
            "Epoch 4/15\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.3438 - loss: 2.3138 - val_accuracy: 0.1613 - val_loss: 29.7498\n",
            "Epoch 5/15\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 1s/step - accuracy: 0.3278 - loss: 2.4815 - val_accuracy: 0.2844 - val_loss: 2.8316\n",
            "Epoch 6/15\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4062 - loss: 2.6550 - val_accuracy: 0.6452 - val_loss: 1.1056\n",
            "Epoch 7/15\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 1s/step - accuracy: 0.4069 - loss: 2.1254 - val_accuracy: 0.3219 - val_loss: 6.7382\n",
            "Epoch 8/15\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4688 - loss: 2.4547 - val_accuracy: 0.6452 - val_loss: 4.2829\n",
            "Epoch 9/15\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 1s/step - accuracy: 0.4702 - loss: 1.9615 - val_accuracy: 0.5031 - val_loss: 1.9114\n",
            "Epoch 10/15\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.3750 - loss: 2.3850 - val_accuracy: 0.8387 - val_loss: 0.4758\n",
            "Epoch 11/15\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 1s/step - accuracy: 0.4701 - loss: 1.9068 - val_accuracy: 0.4344 - val_loss: 3.2698\n",
            "Epoch 12/15\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 1.5590 - val_accuracy: 0.8710 - val_loss: 0.3965\n",
            "Epoch 13/15\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.5144 - loss: 1.7137 - val_accuracy: 0.5312 - val_loss: 4.0904\n",
            "Epoch 14/15\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.6875 - loss: 1.1502 - val_accuracy: 0.7742 - val_loss: 0.8120\n",
            "Epoch 15/15\n",
            "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 1s/step - accuracy: 0.5501 - loss: 1.5882 - val_accuracy: 0.5594 - val_loss: 3.5279\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=15,  # Number of epochs\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_steps=val_generator.samples // val_generator.batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3cWoVps5C_O",
        "outputId": "7654e3f9-b2f7-4677-9dcf-96a6ad4f9444"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d0eea728f40>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Save the model in TensorFlow SavedModel format\n",
        "tf.saved_model.save(\n",
        "    model,  # The model you want to save\n",
        "    export_dir='/content/drive/MyDrive/Kaggle/fruit_model'  # Directory to save the model\n",
        ")\n"
      ],
      "metadata": {
        "id": "LqcRLfb39yr8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install coremltools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-uVPpxuIo_i",
        "outputId": "1cf2db7c-c484-4d2f-9612-968b7dc1f19b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting coremltools\n",
            "  Downloading coremltools-8.1-cp310-none-manylinux1_x86_64.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from coremltools) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from coremltools) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from coremltools) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from coremltools) (4.66.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from coremltools) (24.2)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.10/dist-packages (from coremltools) (24.2.0)\n",
            "Collecting cattrs (from coremltools)\n",
            "  Downloading cattrs-24.1.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pyaml (from coremltools)\n",
            "  Downloading pyaml-24.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs->coremltools) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions!=4.6.3,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from cattrs->coremltools) (4.12.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml->coremltools) (6.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->coremltools) (1.3.0)\n",
            "Downloading coremltools-8.1-cp310-none-manylinux1_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cattrs-24.1.2-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-24.9.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyaml, cattrs, coremltools\n",
            "Successfully installed cattrs-24.1.2 coremltools-8.1 pyaml-24.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import coremltools as ct\n",
        "\n",
        "mlmodel = ct.convert(\n",
        "    '/content/drive/MyDrive/Kaggle/fruit_model',  # Path to the SavedModel directory\n",
        "    source=\"tensorflow\",\n",
        "    inputs=[ct.ImageType(shape=(1, 150, 150, 3))],  # Specify input shape\n",
        "    classifier_config=ct.ClassifierConfig(class_labels=class_names)\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQhA0spUIhYv",
        "outputId": "5e8ac443-925f-47f7-c3ea-2981e418a91e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:coremltools:When both 'convert_to' and 'minimum_deployment_target' not specified, 'convert_to' is set to \"mlprogram\" and 'minimum_deployment_target' is set to ct.target.iOS15 (which is same as ct.target.macOS12). Note: the model will not run on systems older than iOS15/macOS12/watchOS8/tvOS15. In order to make your model run on older system, please set the 'minimum_deployment_target' to iOS14/iOS13. Details please see the link: https://apple.github.io/coremltools/docs-guides/source/target-conversion-formats.html\n",
            "Running TensorFlow Graph Passes: 100%|██████████| 6/6 [00:01<00:00,  4.12 passes/s]\n",
            "Converting TF Frontend ==> MIL Ops: 100%|██████████| 519/519 [00:00<00:00, 1371.11 ops/s]\n",
            "Running MIL frontend_tensorflow2 pipeline: 100%|██████████| 7/7 [00:00<00:00, 39.81 passes/s]\n",
            "Running MIL default pipeline: 100%|██████████| 89/89 [00:05<00:00, 17.04 passes/s]\n",
            "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 38.71 passes/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlmodel.save('/content/drive/MyDrive/Kaggle/fruit/FruitImageClassifier.mlpackage')"
      ],
      "metadata": {
        "id": "HCt3wenKI5q5"
      },
      "execution_count": 19,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}